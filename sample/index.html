<!DOCTYPE html>
<html>

<head>
    <title>test</title>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="keywords" content="" />

    <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,400italic,700,700italic' rel='stylesheet' type='text/css'>

    <link rel="stylesheet" href="./css/style.css" type="text/css" media="all" />
    <link rel="stylesheet" href="./css/TrackDetect.css" type="text/css" media="all" />
</head>
<body style="background-color: white; margin: 0px;">
<div id="cinema" >
    <div id="left-container">
        <a href="https://www.visagetechnologies.com">
            <img src="icons/logotype-tagline-negativ--bw.png" id="logosmall">
        </a>
        <div id="optionbox">
            <div>
                <div class="whitetext">MODE:</div>
                <a href="#" class="tooltip">
                    <button type="Button" class="button" id="ToggleTD" onclick="ToggleTrackDetect();">Switch to Detector</button>
                    <span id="tooltiptext">DETECTOR: Multiple face detection, lower performance and accuracy.</span>
                </a>
            </div>
            <br>
            <div class="whitetext">FACE ANALYSIS:</div>
            <div class="specific">
                <div>
                    <div class="whitetext">GENDER:</div>
                    <button type="Button" class="button" id="ToggleGender" onclick="toggleGender();">Turn OFF</button>
                    <div class="whitetext">AGE:</div>
                    <button type="Button" class="button" id="ToggleAge" onclick="toggleAge();">Turn OFF</button>
                    <div class="whitetext">EMOTIONS:</div>
                    <button type="Button" class="button" id="ToggleEmotions" onclick="toggleEmotions();">Turn OFF</button>
                </div>
            </div>

            <div><br></div>
            <div class="whitetext">DRAW FACIAL FEATURES:</div>
            <div class="specific">
                <div>
                    <div class="whitetext">FEATURE POINTS:</div>
                    <button type="Button" class="button" id="ToggleFP" onclick="toggleFeaturePoints();">Turn OFF</button>
                </div>
                <div id="optionGaze">
                    <div class="whitetext">GAZE:</div>
                    <button type="Button" class="button" id="ToggleGaze" onclick="toggleGaze();">Turn OFF</button>
                </div>
                <div id="optionFMA">
                    <div class="whitetext">FACE MODEL AXIS:</div>
                    <button type="Button" class="button" id="ToggleFMA" onclick="toggleFMA();">Turn OFF</button>
                </div>
            </div>
        </div>
        <br>
        <div class="toolbox">
            <select id="myList" onchange="testConfig()">
                <option>Facial Features Tracker - High.cfg</option>
                <option>Facial Features Tracker - Low.cfg</option>
                <option>Head Tracker.cfg</option>
            </select>
        </div>

    </div>

    <div id="outer-container">
        <div id="tracktext">
            <p class="whitetextcenter" align="center">TRACKER: Single-face tracking, higher performance and accuracy.</p>
        </div>
        <div id="detecttext">
            <p class="whitetextcenter" align="center">DETECTOR: Multiple face detection, lower performance and accuracy.</p>
        </div>

        <div id="downloadinfo" align="center">
            <div  id="status" align="center">Downloading...</div>
            <div id="loadbar">
                <progress value="0" max="100" id="progress" hidden=1></progress>
            </div>
        </div>

        <div id="inner-container">
            <img src="icons/logotype-tagline-negativ--bw.png" id="logogrey">
            <canvas id="canvas"></canvas>
        </div>
    </div>

    <div id="right-container">

        <br>
        <div id="data" style= "padding: 10px">
            <p class="whitetext"><b>RESULTS:</b></p>
            <br>
            <p class="whitetext">FRAME RATE: <b id="boldStuff">29.3fps</b> </p>
            <p class="vanishing">TRANSLATION: <b id="myTrans">----</b> </p>
            <p class="vanishing">ROTATION: <b id="myRot">----</b> </p>
            <p class="vanishing">STATUS: <b id="myStat">[TRACK_STAT_OFF]</b> </p>
        </div>
        <br>
    </div>
</div>
</body>

<script type="text/javascript">
    var Module =
    {
        onRuntimeInitialized: function()
        {
            onModuleInitialized();
        }
    };
</script>
<script src="bezier-spline.js"></script>

<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/1.3.2/jquery.min.js"></script>

<script type='text/javascript'>

    function toggleSlider() {
        if ($("#panelThatSlides").is(":visible")) {
            $("#contentThatFades").fadeOut(600, function(){
                $("#panelThatSlides").slideUp();
            });
        }
        if ($("#panelThatSlides2").is(":visible")) {
            $("#contentThatFades2").fadeOut(600, function(){
                $("#panelThatSlides2").slideUp();
            });
        }
        else {
            $("#panelThatSlides").slideDown(600, function(){
                $("#contentThatFades").fadeIn();
            });
        }
    }

    //VARS
    //**********
    var fpsOut = document.getElementById('boldStuff');
    var transOutput = document.getElementById('myTrans'),
            rotOutput = document.getElementById('myRot'),
            statOutput = document.getElementById('myStat'),
            canvas = document.getElementById('canvas');

    var mWidth = 0,
            mHeight = 0;

    var fps = 0,
            now = 0,
            lastUpdate = 0
    fpsFilter = 50;

    var minFaceScale = 0;

    var MODE_DETECT = 1;
    var MODE_TRACK = 0;
    var activeMode = MODE_TRACK;

    var canCon = canvas.getContext('2d');
    var startTracking = false;
    var draw = true;
    var thisFrameFPS = 10;

    var splineResolution = 5;

    var IRIS_COLOR			=	"rgba(200,80,0,255)",
            GAZE_COLOR			=	"rgba(240,96,0,255)",
            BLACK_COLOR			=	"#000000",
            POINTS_COLOR		=	"rgba(0,255,255,255)",
            SPLINES_COLOR		=	"rgba(176,196,222,160)",
            X_AXIS_COLOR		=	"rgba(255,0,0,0.2)",
            Y_AXIS_COLOR		=	"rgba(0,255,0,0.2)",
            Z_AXIS_COLOR		=	"rgba(0,0,255,1)",
            MALE_GENDER			=	"rgba(0,0,255,0.8)",
            FEMALE_GENDER		=	"rgba(255,0,0,0.8)";

    var styles = {'LINE' : 0, 'LINELOOP' : 1, 'POINT' : 2, 'SPLINE' : 3}

    //Gender control (ON/OFF)
    function toggleGender()
    {
        if(drawGender)
        {
            document.getElementById('ToggleGender').innerHTML = "Turn ON";
        }
        else
        {
            document.getElementById('ToggleGender').innerHTML = "Turn OFF";
        }
        drawGender = !drawGender;
    }

    //Emotion control (ON/OFF)
    function toggleEmotions()
    {
        if(drawEmotions)
        {
            document.getElementById('ToggleEmotions').innerHTML = "Turn ON";
        }
        else
        {
            document.getElementById('ToggleEmotions').innerHTML = "Turn OFF";
        }
        drawEmotions = !drawEmotions;
    }

    //Age control (ON/OFF)
    function toggleAge()
    {
        if(drawAge)
        {
            document.getElementById('ToggleAge').innerHTML = "Turn ON";
        }
        else
        {
            document.getElementById('ToggleAge').innerHTML = "Turn OFF";
        }
        drawAge = !drawAge;
    }

    //FPS - Refreshes FPS display every 1000ms
    setInterval(function(){
        fpsOut.innerHTML = fps.toFixed(1) + "fps";
    }, 10);

    /*
     * Draw spline
     */
    function drawSpline2D(points, color, resolution)
    {
        var oldWidth = canCon.lineWidth;
        var step = 1 / resolution;

        canCon.beginPath();
        canCon.strokeStyle = color;
        canCon.lineWidth = 0.05;
        canCon.moveTo(points[0], points[1]);

        var newPoints = [];

        for (var i = 0; i < resolution; i++)
        {
            var t = step * i;
            var B0 = Math.pow((1-t), 3)
            var B1 = 3 * t * Math.pow((1-t), 2);
            var B2 = 3 * Math.pow(t, 2) * (1-t)
            var B3 = Math.pow(t, 3);

            var px = (B0 * points[0]) + (B1 * points[2]) + (B2 * points[4]) + (B3 * points[6]);
            var py = (B0 * points[1]) + (B1 * points[3]) + (B2 * points[5]) + (B3 * points[7]);

            newPoints.push([px, py]);
        }

        newPoints.push([points[6], points[7]]);

        for (var i = 1; i < newPoints.length; i++)
        {
            canCon.lineTo(newPoints[i][0], newPoints[i][1]);
            canCon.stroke();
        }

        canCon.closePath();
        canCon.lineWidth = oldWidth;
    }

    /*
     * Draw lines using canvas draw methods
     */
    function drawPoints2D(points, pointsNum, style, featurePoints2D, color, radius)
    {
        V = [];

        canCon.beginPath();
        canCon.closePath();

        var n = 0;
        for (var i = 0; i < pointsNum*2; i+=2){
            if (featurePoints2D.FPIsDefined(points[i],points[i+1]) === true){
                var x = featurePoints2D.getFPPos(points[i],points[i+1])[0]*canvas.width;
                var y = (1 - featurePoints2D.getFPPos(points[i],points[i+1])[1])*canvas.height;

                if (style === styles.SPLINE)
                    createKnot(x,y);
                else
                {
                    if (style === styles.POINT){
                        canCon.beginPath();
                        canCon.fillStyle = BLACK_COLOR;
                        canCon.arc(x,y,radius,0,2*Math.PI,true);
                        canCon.closePath();
                        canCon.fill();
                        //
                        canCon.beginPath();
                        canCon.fillStyle = color;
                        canCon.arc(x,y,radius*0.6,0,2*Math.PI,true);
                        canCon.closePath();
                        canCon.fill();
                    }
                    if (style === styles.LINE){
                        if (n%2 === 0){
                            canCon.beginPath();
                            canCon.moveTo(x,y);
                        }
                        else {
                            canCon.lineTo(x,y);
                            canCon.strokeStyle = color;
                            canCon.stroke();
                            canCon.closePath();
                        }
                    }
                    if (style === styles.LINELOOP){
                        if (n==0){
                            canCon.beginPath();
                            canCon.moveTo(x,y);
                        }
                        else{
                            canCon.lineTo(x,y);
                            canCon.strokeStyle = color;
                            canCon.stroke();
                            canCon.closePath();
                            canCon.beginPath();
                            canCon.moveTo(x,y);
                        }
                    }
                }

                n++;
            }
        }

        if (style === styles.SPLINE)
        {
            updateSplines();

            for (var m=0; m< S.length;m++)
            {
                for (var l=0; l< S[m].length;l+=2)
                {
                    drawSpline2D (S[m], color, splineResolution);
                }
            }
        }



        if (style == styles.LINELOOP){
            var x = featurePoints2D.getFPPos(points[0],points[1])[0]*canvas.width;
            var y = (1 - featurePoints2D.getFPPos(points[0],points[1])[1])*canvas.height;
            canCon.lineTo(x,y);
            canCon.strokeStyle = color;
            canCon.stroke();
            canCon.closePath();
        }
    }

    /*
     * Draw facial features
     */
    function drawFaceFeatures(faceData)
    {
        var radius = (faceData.faceScale / mWidth) * 10;

        var chinPoints = [
            2,	1,
        ]

        drawPoints2D(chinPoints, 1, styles.POINT,  faceData.getFeaturePoints2D(),POINTS_COLOR,radius);


        var innerLipPoints = [
            2,	2,
            2,	6,
            2,	4,
            2,	8,
            2,	3,
            2,	9,
            2,	5,
            2,	7,
        ]

        var upperInnerLipPoints = [
            2,	5,
            2,	7,
            2,	2,
            2,	6,
            2,	4,
        ]

        var lowerInnerLipPoints = [
            2,	5,
            2,	9,
            2,	3,
            2,	8,
            2,	4,
        ]

        drawPoints2D(upperInnerLipPoints, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(lowerInnerLipPoints, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(innerLipPoints, 8, styles.POINT, faceData.getFeaturePoints2D(), POINTS_COLOR,radius);

        var outerLipPoints = [
            8,	1,
            8,	10,
            8,	5,
            8,	3,
            8,	7,
            8,	2,
            8,	8,
            8,	4,
            8,	6,
            8,	9,
        ]

        var upperOuterLipPointsLeft = [
            8,	4,
            8,	6,
            8,	9,
            8,	1,
        ]

        var upperOuterLipPointsRight = [
            8,	1,
            8,	10,
            8,	5,
            8,	3,
        ]

        var lowerOuterLipPoints = [
            8,	4,
            8,	8,
            8,	2,
            8,	7,
            8,	3,
        ]

        drawPoints2D(upperOuterLipPointsLeft, 4, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(upperOuterLipPointsRight, 4, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(lowerOuterLipPoints, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(outerLipPoints, 10, styles.POINT,faceData.getFeaturePoints2D(),POINTS_COLOR,radius);

        var nosePoints = [
            9,	1,
            9,	2,
            9,	3,
            9,	15,
        ]
        var noseLinesPoints = [
            9,	1,
            9,	3,
            9,	2
        ]

        drawPoints2D(nosePoints, 4, styles.POINT,faceData.getFeaturePoints2D(),POINTS_COLOR,radius);
        drawPoints2D(noseLinesPoints, 3, styles.SPLINE,faceData.getFeaturePoints2D(),SPLINES_COLOR);

        if(faceData.getEyeClosure()[0])
        {
            //if eye is open, draw the iris
            var irisPoints = [
                3,	6,
            ]
            drawPoints2D(irisPoints, 1,styles.POINT, faceData.getFeaturePoints2D(),IRIS_COLOR,radius);
        }

        if(faceData.getEyeClosure()[1])
        {
            //if eye is open, draw the iris
            var irisPoints = [
                3,	5,
            ]
            drawPoints2D(irisPoints, 1,styles.POINT, faceData.getFeaturePoints2D(),IRIS_COLOR,radius);
        }

        var eyesPointsR = [
            3,	2,
            3,	4,
            3,	8,
            3,	10,
            3,	12,
            3,	14,
            12, 6,
            12, 8,
            12, 10,
            12, 12,
        ]
        var eyesPointsL = [
            3,	1,
            3,	3,
            3,	7,
            3,	9,
            3,	11,
            3,	13,
            12, 5,
            12, 7,
            12, 9,
            12, 11,
        ]
        var rightEyeOuterUpper = [
            3,	12,
            3,	14,
            3,	8,
        ]
        var rightEyeOuterLower = [
            3,	12,
            3,	10,
            3,	8,
        ]
        var rightEyeInnerUpper = [
            3,	12,
            12, 10,
            3,	2,
            12, 6,
            3,	8,
        ]
        var rightEyeInnerLower = [
            3,	12,
            12, 12,
            3,	4,
            12,	8,
            3,	8,
        ]

        var leftEyeOuterUpper = [
            3,	11,
            3,	13,
            3,	7,
        ]
        var leftEyeOuterLower = [
            3,	11,
            3,	9,
            3,	7,
        ]
        var leftEyeInnerUpper = [
            3,	11,
            12, 9,
            3,	1,
            12, 5,
            3,	7,
        ]
        var leftEyeInnerLower = [
            3,	11,
            12, 11,
            3,	3,
            12,	7,
            3,	7,
        ]

        //draw points for right eye
        if(faceData.getEyeClosure()[1])
        {
            drawPoints2D(eyesPointsR, 10, styles.POINT,faceData.getFeaturePoints2D(),POINTS_COLOR,radius);
        }
        else if (!faceData.getEyeClosure()[1])
        {
            drawPoints2D(eyesPointsR, 10, styles.POINT,faceData.getFeaturePoints2D(),BLACK_COLOR,radius);
        }

        //draw points for left eye
        if(faceData.getEyeClosure()[0])
        {
            drawPoints2D(eyesPointsL, 10, styles.POINT,faceData.getFeaturePoints2D(),POINTS_COLOR,radius);
        }
        else if (!faceData.getEyeClosure()[0])
        {
            drawPoints2D(eyesPointsL, 10, styles.POINT,faceData.getFeaturePoints2D(),BLACK_COLOR,radius);
        }

        //draw lines for both eyes
        drawPoints2D(rightEyeOuterUpper, 3, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(rightEyeOuterLower, 3, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(rightEyeInnerUpper, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(rightEyeInnerLower, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        //
        drawPoints2D(leftEyeOuterUpper, 3, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(leftEyeOuterLower, 3, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(leftEyeInnerUpper, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(leftEyeInnerLower, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);

        //draw eyebrows
        var eyebrowPoints = [
            4,	1,
            4,	2,
            4,	3,
            4,	4,
            4,	5,
            4,	6,
            14, 1,
            14, 2,
            14, 3,
            14, 4,
        ]
        var leftEyebrow = [
            4,	6,
            14, 4,
            4,	4,
            14, 2,
            4,	2,
        ]
        var rightEyebrow = [
            4,	1,
            14, 1,
            4,	3,
            14, 3,
            4,	5,
        ]

        drawPoints2D(leftEyebrow, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(rightEyebrow, 5, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(eyebrowPoints, 10, styles.POINT,faceData.getFeaturePoints2D(),POINTS_COLOR,radius);

        // visible contour
        var contourPointsVisible = [
            13,	1,
            13,	3,
            13,	5,
            13,	7,
            13,	9,
            13,	11,
            13,	13,
            13,	15,
            13,	17,
            13,	16,
            13,	14,
            13,	12,
            13,	10,
            13,	8,
            13,	6,
            13,	4,
            13,	2
        ]

        drawPoints2D(contourPointsVisible, 17, styles.SPLINE, faceData.getFeaturePoints2D(), SPLINES_COLOR);
        drawPoints2D(contourPointsVisible, 17, styles.POINT, faceData.getFeaturePoints2D(), POINTS_COLOR,radius);
    }

    function testConfig(){
        var mylist=document.getElementById("myList");
        var cfgPath = "../../lib/"+mylist.options[mylist.selectedIndex].text;
        if(activeMode == MODE_TRACK)
        {
            m_Tracker.setTrackerConfiguration(cfgPath);
        }
    }

    function multiplyMatrix(m1, m2, M, N, P) {

        var res = [];
        for(var i = 0; i < M; ++i)
        {
            for(var j = 0; j < P; ++j)
            {
                var sum = 0;
                for(var k = 0; k < N; ++k)
                {
                    sum = sum + m1[i*N+k] * m2[k*P+j];
                }
                res[i*P+j] = sum;
            }
        }

        return res;
    }

    function drawFaceModelAxes(trackData){

        //set projection
        var f = 3;

        var x_offset = 1;
        var y_offset = 1;


        if (canvas.width > canvas.height)
            x_offset = canvas.width / canvas.height;
        else if (canvas.width < canvas.height)
            y_offset = canvas.height / canvas.width;


        var frustum_near = 0.001;
        var frustum_far = 30;
        var frustum_x = x_offset*frustum_near/f;
        var frustum_y = y_offset*frustum_near/f;

        var A = (frustum_x - frustum_x)/(frustum_x + frustum_x);
        var B = (frustum_y - frustum_y)/(frustum_y + frustum_y);
        var C = - ((frustum_far + frustum_near)/(frustum_far - frustum_near));
        var D = - ((2*frustum_near*frustum_far)/(frustum_far-frustum_near));
        var x1 = (2*frustum_near)/(frustum_x+frustum_x);
        var y2 = (2*frustum_near)/(frustum_y+frustum_y);
        var frustumMatrix = [x1, 0,	 0,	 0,
            0,	y2, 0,	0,
            A,	B,	C, -1,
            0,	0,	D,	0 ];

        var camera = [0, 0, 10];
        var origin = [0, 0, 0];
        var destX = [-1, 0, 0];
        var destY = [0, -1, 0];
        var destZ = [0, 0, 1];

        var sinrx = Math.sin(-trackData.getFaceRotation()[0]);
        var sinry = Math.sin(trackData.getFaceRotation()[1]);
        var sinrz = Math.sin(-trackData.getFaceRotation()[2]);
        var cosrx = Math.cos(trackData.getFaceRotation()[0]);
        var cosry = Math.cos(trackData.getFaceRotation()[1]);
        var cosrz = Math.cos(trackData.getFaceRotation()[2]);

        //set the rotation matrix
        var R00 = cosry*cosrz+sinrx*sinry*sinrz;
        var R01 = -cosry*sinrz+sinrx*sinry*cosrz;
        var R02 = cosrx*sinry;
        var R10 = cosrx*sinrz;
        var R11 = cosrx*cosrz;
        var R12 = -sinrx;
        var R20 = -sinry*cosrz+sinrx*cosry*sinrz;
        var R21 = sinry*sinrz+sinrx*cosry*cosrz;
        var R22 = cosrx*cosry;

        //apply rotation
        var dest_new_origin = [0,0,0];
        dest_new_origin[0] = 1*(R00*origin[0]+R01*origin[1]+R02*origin[2]);
        dest_new_origin[1] = 1*(R10*origin[0]+R11*origin[1]+R12*origin[2]);
        dest_new_origin[2] = 1*(R20*origin[0]+R21*origin[1]+R22*origin[2]);

        var dest_new_x = [0,0,0];
        dest_new_x[0] = 1*(R00*destX[0]+R01*destX[1]+R02*destX[2]);
        dest_new_x[1] = 1*(R10*destX[0]+R11*destX[1]+R12*destX[2]);
        dest_new_x[2] = 1*(R20*destX[0]+R21*destX[1]+R22*destX[2]);

        var dest_new_y = [0,0,0];
        dest_new_y[0] = 1*(R00*destY[0]+R01*destY[1]+R02*destY[2]);
        dest_new_y[1] = 1*(R10*destY[0]+R11*destY[1]+R12*destY[2]);
        dest_new_y[2] = 1*(R20*destY[0]+R21*destY[1]+R22*destY[2]);

        var dest_new_z = [0,0,0];
        dest_new_z[0] = 1*(R00*destZ[0]+R01*destZ[1]+R02*destZ[2]);
        dest_new_z[1] = 1*(R10*destZ[0]+R11*destZ[1]+R12*destZ[2]);
        dest_new_z[2] = 1*(R20*destZ[0]+R21*destZ[1]+R22*destZ[2]);

        //project on the screen
        var destPomOrigin = [dest_new_origin[0],dest_new_origin[1],dest_new_origin[2] - camera[2],1];
        var resultOrigin = multiplyMatrix(destPomOrigin,frustumMatrix,1,4,4);

        var destPomX = [dest_new_x[0],dest_new_x[1],dest_new_x[2] - camera[2],1];
        var resultX = multiplyMatrix(destPomX,frustumMatrix,1,4,4);

        var destPomY = [dest_new_y[0],dest_new_y[1],dest_new_y[2] - camera[2],1];
        var resultY = multiplyMatrix(destPomY,frustumMatrix,1,4,4);
        //
        var destPomZ = [dest_new_z[0],dest_new_z[1],dest_new_z[2] - camera[2],1];
        var resultZ = multiplyMatrix(destPomZ,frustumMatrix,1,4,4);

        var left_eyebrow = trackData.getFeaturePoints2D().getFP(4,1);
        var right_eyebrow = trackData.getFeaturePoints2D().getFP(4,2);

        var center_position = [];

        if (left_eyebrow.defined === 1 && right_eyebrow.defined === 1){
            center_position[0] = (left_eyebrow.getPos(0) +	right_eyebrow.getPos(0))/2.0;
            center_position[1] = 1-((left_eyebrow.getPos(1) +  right_eyebrow.getPos(1))/2.0);
        }

        var center_pos = [center_position[0]*canvas.width, center_position[1]*canvas.height];

        var dest = [0, 0, 0];
        var destOrigin = [0, 0, 0];


        destOrigin[0] = (resultOrigin[0]/resultOrigin[3] + 1) * canvas.width / 2;
        destOrigin[1] = (resultOrigin[1]/resultOrigin[3] + 1) * canvas.height / 2;
        destOrigin[2] = (resultOrigin[2]/resultOrigin[3] + 1) / 2;

        dest[0] = (resultX[0]/resultX[3] + 1) * canvas.width / 2;
        dest[1] = (resultX[1]/resultX[3] + 1) * canvas.height / 2;
        dest[2] = (resultX[2]/resultX[3] + 1) / 2;

        //draw x axis
        canCon.beginPath();
        canCon.moveTo(center_pos[0],center_pos[1]);
        canCon.lineTo(center_pos[0]+(dest[0]- destOrigin[0]),(center_pos[1]+(dest[1]-destOrigin[1])));
        canCon.strokeStyle = X_AXIS_COLOR;
        canCon.lineWidth = 3;
        canCon.stroke();
        canCon.closePath();

        dest[0] = (resultY[0]/resultY[3] + 1) * canvas.width / 2;
        dest[1] = (resultY[1]/resultY[3] + 1) * canvas.height / 2;
        dest[2] = (resultY[2]/resultY[3] + 1) / 2;

        //draw y axis
        canCon.beginPath();
        canCon.moveTo(center_pos[0],center_pos[1]);
        canCon.lineTo(center_pos[0]+(dest[0]- destOrigin[0]),(center_pos[1]+(dest[1]-destOrigin[1])));
        canCon.strokeStyle = Y_AXIS_COLOR;
        canCon.lineWidth = 3;
        canCon.stroke();
        canCon.closePath();

        dest[0] = (resultZ[0]/resultZ[3] + 1) * canvas.width / 2;
        dest[1] = (resultZ[1]/resultZ[3] + 1) * canvas.height / 2;
        dest[2] = (resultZ[2]/resultZ[3] + 1) / 2;

        //draw z axis
        canCon.beginPath();
        canCon.moveTo(center_pos[0],center_pos[1]);
        canCon.lineTo(center_pos[0]+(dest[0]- destOrigin[0]),(center_pos[1]+(dest[1]-destOrigin[1])));
        canCon.strokeStyle = Z_AXIS_COLOR;
        canCon.lineWidth = 3;
        canCon.stroke();
        canCon.closePath();
    }

    function drawGaze(trackData){
        if(activeMode == MODE_TRACK)
        {
            if (!trackData.getEyeClosure()[1])
                return;
        }
        if(activeMode == MODE_DETECT)
        {
            if (!trackData.getEyeClosure()[1])
                return;
        }
        //set projection
        var f = trackData.cameraFocus;
        var x_offset = 1;
        var y_offset = 1;

        if (canvas.width > canvas.height)
            x_offset = canvas.width / canvas.height;
        else if (canvas.width < canvas.height)
            y_offset = canvas.height / canvas.width;

        var frustum_near = 0.001;
        var frustum_far = 30;
        var frustum_x = x_offset*frustum_near/f;
        var frustum_y = y_offset*frustum_near/f;

        var A = (frustum_x - frustum_x)/(frustum_x + frustum_x);
        var B = (frustum_y - frustum_y)/(frustum_y + frustum_y);
        var C = - ((frustum_far + frustum_near)/(frustum_far - frustum_near));
        var D = - ((2*frustum_near*frustum_far)/(frustum_far-frustum_near));
        var x1 = (2*frustum_near)/(frustum_x+frustum_x);
        var y2 = (2*frustum_near)/(frustum_y+frustum_y);
        var frustumMatrix = [x1, 0,	 0,	 0,
            0,	y2, 0,	0,
            A,	B,	C, -1,
            0,	0,	D,	0 ];

        var dest = [0,0,1];
        var camera = [0,0,10];
        var origin = [0,0,0];

        var sinrx = Math.sin(trackData.getGazeDirectionGlobal()[0]);
        var sinry = Math.sin(trackData.getGazeDirectionGlobal()[1]);
        var sinrz = Math.sin(trackData.getGazeDirectionGlobal()[2]);
        var cosrx = Math.cos(trackData.getGazeDirectionGlobal()[0]);
        var cosry = Math.cos(trackData.getGazeDirectionGlobal()[1]);
        var cosrz = Math.cos(trackData.getGazeDirectionGlobal()[2]);

        //set the rotation matrix
        var R00 = cosry*cosrz+sinrx*sinry*sinrz;
        var R01 = -cosry*sinrz+sinrx*sinry*cosrz;
        var R02 = cosrx*sinry;
        var R10 = cosrx*sinrz;
        var R11 = cosrx*cosrz;
        var R12 = -sinrx;
        var R20 = -sinry*cosrz+sinrx*cosry*sinrz;
        var R21 = sinry*sinrz+sinrx*cosry*cosrz;
        var R22 = cosrx*cosry;

        //apply rotation
        var dest_new = [0,0,0];
        dest_new[0] = 1*(R00*dest[0]+R01*dest[1]+R02*dest[2]);
        dest_new[1] = 1*(R10*dest[0]+R11*dest[1]+R12*dest[2]);
        dest_new[2] = 1*(R20*dest[0]+R21*dest[1]+R22*dest[2]);

        var dest_new_origin = [0,0,0];
        dest_new_origin[0] = 1*(R00*origin[0]+R01*origin[1]+R02*origin[2]);
        dest_new_origin[1] = 1*(R10*origin[0]+R11*origin[1]+R12*origin[2]);
        dest_new_origin[2] = 1*(R20*origin[0]+R21*origin[1]+R22*origin[2]);

        //project on the screen
        var destPomOrigin = [dest_new_origin[0],dest_new_origin[1],dest_new_origin[2]-camera[2],1];
        var resultOrigin = multiplyMatrix(destPomOrigin,frustumMatrix,1,4,4);

        var destPom = [dest_new[0],dest_new[1],dest_new[2]-camera[2],1];
        var result = multiplyMatrix(destPom,frustumMatrix,1,4,4);


        resultOrigin[0] = (resultOrigin[0]/resultOrigin[3] + 1)/2;
        resultOrigin[1] = (resultOrigin[1]/resultOrigin[3] + 1)/2;
        resultOrigin[2] = (resultOrigin[2]/resultOrigin[3] + 1)/2;

        result[0] = (result[0]/result[3] + 1)/2;
        result[1] = (result[1]/result[3] + 1)/2;
        result[2] = (result[2]/result[3] + 1)/2;


        var left_eye_2d_fp = trackData.getFeaturePoints2D().getFP(3,5);
        var right_eye_2d_fp = trackData.getFeaturePoints2D().getFP(3,6);

        var left_eye_2d_pos = [];
        var right_eye_2d_pos = [];

        if (left_eye_2d_fp.defined === 1 && right_eye_2d_fp.defined === 1){
            left_eye_2d_pos[0] = left_eye_2d_fp.getPos(0);
            left_eye_2d_pos[1] = left_eye_2d_fp.getPos(1);
            right_eye_2d_pos[0] = right_eye_2d_fp.getPos(0);
            right_eye_2d_pos[1] = right_eye_2d_fp.getPos(1);
        }

        //apply translation
        var left_gaze_x = result[0] - resultOrigin[0] + left_eye_2d_pos[0];
        var left_gaze_y = result[1] - resultOrigin[1] + left_eye_2d_pos[1];

        var right_gaze_x = result[0] - resultOrigin[0] + right_eye_2d_pos[0];
        var right_gaze_y = result[1] - resultOrigin[1] + right_eye_2d_pos[1];

        //draw left eye gaze
        canCon.beginPath();
        canCon.moveTo(left_eye_2d_pos[0]*canvas.width,(1 - left_eye_2d_pos[1])*canvas.height);
        canCon.lineTo(left_gaze_x*canvas.width,(1 - left_gaze_y)*canvas.height);
        canCon.strokeStyle = GAZE_COLOR;
        canCon.lineWidth = 2;
        canCon.stroke();
        canCon.closePath();

        //draw right eye gaze
        canCon.beginPath();
        canCon.moveTo(right_eye_2d_pos[0]*canvas.width,(1 - right_eye_2d_pos[1])*canvas.height);
        canCon.lineTo(right_gaze_x*canvas.width,(1 - right_gaze_y)*canvas.height);
        canCon.strokeStyle = GAZE_COLOR;
        canCon.lineWidth = 2;
        canCon.stroke();
    }

    var drawAge = true;
    var drawGender = true;
    var drawEmotions = true;
    //Draws the emotion box with gender, age and emotion estimation. Argument 'index' is used by detector for multiple faces.
    function drawGenderAgeEmotions(emotion_values,gender,age,index)
    {
        var x;
        var y;
        var isTracker = (typeof index === 'undefined');
        if (isTracker)
        {
            //Anchors the emotion box on the chin (tracker)
            x = (1 - TfaceData.getFeaturePoints2D().getFPPos(2,1)[0])*canvas.width;
            y = (1 - TfaceData.getFeaturePoints2D().getFPPos(2,1)[1])*canvas.height;
        }
        else
        {
            //Anchors the emotion box on the chin of the respective face (detector)
            x = (1 - DfaceData.get(index).getFeaturePoints2D().getFPPos(2,1)[0])*canvas.width;
            y = (1 - DfaceData.get(index).getFeaturePoints2D().getFPPos(2,1)[1])*canvas.height;
        }

        var verticalStep = 12;
        var emotionsBarOffset = 70;
        var emotionPos = 2;

        var emotions = ["Anger", "Disgust", "Fear", "Happiness", "Sadness", "Surprise", "Neutral"];
        canCon.fillStyle="rgba(255,255,255,0.5)";

        if((isTracker &&
                Math.abs(TfaceData.getFaceRotation()[0]) < 0.5 &&
                Math.abs(TfaceData.getFaceRotation()[1]) < 0.35 &&
                Math.abs(TfaceData.getFaceRotation()[2]) < 0.35 &&
                TfaceData.getFaceTranslation()[2] < 1)
                ||
                (!isTracker &&
                Math.abs(DfaceData.get(index).getFaceRotation()[0]) < 0.5 &&
                Math.abs(DfaceData.get(index).getFaceRotation()[1]) < 0.35 &&
                Math.abs(DfaceData.get(index).getFaceRotation()[2]) < 0.35 &&
                DfaceData.get(index).getFaceTranslation()[2] < 1))
        {
            if(drawEmotions)
            {
                if(drawGender ||  drawAge){
                    emotionPos = 2;
                    canCon.fillRect(x-5,y-15,180,120);
                }
                else
                {
                    emotionPos = 0;
                    canCon.fillRect(x-5,y-15,180,100);
                }
            }
            else
            {
                if(drawGender || drawAge){
                    emotionPos = 2;
                    canCon.fillRect(x-5,y-15,130,25);
                }
                else
                {
                    return;
                }
            }
            if(drawGender && drawAge)
            {
                canCon.beginPath();
                canCon.fillStyle="black";
                canCon.font = "15px Arial";
                if(gender)
                {
                    canCon.fillText("MALE, Age: "+ Math.round(age),x,y);
                }
                else
                {
                    canCon.fillText("FEMALE, Age: "+ Math.round(age),x,y);
                }

                canCon.closePath();
            }
            else if(drawGender)
            {
                canCon.beginPath();
                canCon.fillStyle="black";
                canCon.font = "15px Arial";
                if(gender)
                {
                    canCon.fillText("Gender: MALE",x,y);
                }
                else
                {
                    canCon.fillText("Gender: FEMALE",x,y);
                }
                canCon.closePath();
            }
            else if(drawAge)
            {
                canCon.beginPath();
                canCon.fillStyle="black";
                canCon.font = "15px Arial";
                canCon.fillText("Age: "+ Math.round(age),x,y);
                canCon.closePath();

            }

            if(drawEmotions && (drawAge || drawGender))
            {
                canCon.beginPath();
                canCon.moveTo(x,y + 6);
                canCon.lineTo(x + 160,y +6);
                canCon.strokeStyle = "black";
                canCon.lineWidth = 1;
                canCon.stroke();
                canCon.closePath();
            }

            if(drawEmotions)
            {
                for(var j = 0; j < numberOfEmotions; ++j)
                {
                    var length = emotion_values[j] * 100;
                    canCon.beginPath();
                    canCon.fillStyle="black";
                    canCon.font = "15px Arial";
                    canCon.fillText(emotions[j],x,y + (j + emotionPos) * verticalStep);
                    canCon.moveTo(x + emotionsBarOffset,y - 3 + (j + emotionPos) * verticalStep);
                    canCon.lineTo(x + emotionsBarOffset + length,y - 3 + (j + emotionPos) * verticalStep);
                    canCon.strokeStyle = Z_AXIS_COLOR;
                    canCon.lineWidth = 6;
                    canCon.stroke();
                    canCon.closePath();
                }
            }
        }
        else
        {
            canCon.fillRect(x-5,y-15,170,80);
            canCon.beginPath();
            canCon.fillStyle="red";
            canCon.font = "15px Arial";
            canCon.fillText("Age, gender and emotion ",x,y);
            canCon.fillText("estimation available ",x,y+15);
            canCon.fillText("only in frontal pose",x,y+30);
            canCon.fillText("and if face is fairly",x,y+45);
            canCon.fillText("close to the camera.",x,y+60);

            canCon.closePath();
        }
    }

    //controls the drawing of facial features (tracker and detector)
    var statusFeaturePoints = true;
    function toggleFeaturePoints()
    {
        statusFeaturePoints = !statusFeaturePoints;
        if(statusFeaturePoints)
        {
            document.getElementById('ToggleFP').innerHTML = "Turn OFF";
        }
        else
        {
            document.getElementById('ToggleFP').innerHTML = "Turn ON";
        }
    }

    //controls the drawing of eye gaze (tracker)
    var statusGaze = true;
    function toggleGaze()
    {
        statusGaze = !statusGaze;
        if(statusGaze)
        {
            document.getElementById('ToggleGaze').innerHTML = "Turn OFF";
        }
        else
        {
            document.getElementById('ToggleGaze').innerHTML = "Turn ON";
        }
    }

    //controls the drawing of face model axis (tracker)
    statusFMA = true;
    function toggleFMA()
    {
        statusFMA = !statusFMA;
        if(statusFMA)
        {
            document.getElementById('ToggleFMA').innerHTML = "Turn OFF";
        }
        else
        {
            document.getElementById('ToggleFMA').innerHTML = "Turn ON";
        }
    }


    var currentOpacity;

    /*
     * Callback method mentioned in the documentation.
     * Gets executed after all the preparation is done (all the files have been downloaded) and tracker is ready to start tracking.
     * In this case it enables buttons on the page.
     */
    function callbackDownload(){
        //Start tracking
        StartTracker();
    }

    var trackerStates = ["TRACK_STAT_OFF","TRACK_STAT_OK","TRACK_STAT_RECOVERING","TRACK_STAT_INIT"];
    var trackerReturnState = trackerStates[0];

    var frameSample = [0,0,0,0,0];
    var newSample = [0,0,0,0,0];
    var ppixels,
            pixels;

    /*
     * Compares two samples of 5 pixel values
     */
    function checkFrameDuplicate(newSample){
        for (var i = 0; i <	 newSample.length; i+=2){
            if (newSample[i]!==frameSample[i])
                return false;
        }
        //additional check
        for (var i = 1; i < newSample.length; i+= 2)
        {
            if (newSample[i]!==frameSample[i])
                return false;
        }
        return true;
    }

    function sortFunction(a, b) {
        if (a[1] === b[1]) {
            return 0;
        }
        else {
            return (a[1] < b[1]) ? -1 : 1;
        }
    }

    //matches detected faces with data from the previous frames
    function matchFaces(){
        //detectOldFaces[x]: 0:last frame index || 1:current index || 2:difference from last frame || 3:head center X || 4:head center Y || 5:list for emotion filter || 6:list for gender filter || 7:list for age filter
        //Contains the data for gender and emotion estimation from the previous frames
        if(detectOldFaces.length == 0)
        {
            for (var i = 0; i < numOfFaces; i++)
            {
                var fpPos = DfaceData.get(i).getFeaturePoints2D().getFPPos(12,1);
                detectOldFaces[i] = new Array(i,i,0,fpPos[0],fpPos[1],new Array(),new Array(),new Array());
            }
        }
        else
        {
            //destructableArray[x]: 0:last frame index || 1:current index || 2:difference from last frame || 3:head center X || 4:head center Y || 5:list for emotion filter || 6:list for gender filter || 7:list for age filter
            //Same structure as detectOldFaces, it is used to match old gender and emotion data with the current frame
            var destructableArray = new Array();
            var tempDetectOldFaces = new Array();

            for (var j = 0; j < detectOldFaces.length; j++)
            {
                for (var i = 0; i < numOfFaces; i++)
                {
                    var fpPos = DfaceData.get(i).getFeaturePoints2D().getFPPos(12,1);
                    //calculates the difference of head positions in old frames with the head positions from the new frame and creates a matrix (destructableArray) witch is used to match faces
                    var faceDif = Math.abs(fpPos[0] - detectOldFaces[j][3]) +
                            Math.abs(fpPos[1] - detectOldFaces[j][4]);

                    destructableArray.push(new Array(j,i,faceDif,fpPos[0],fpPos[1],detectOldFaces[j][5],detectOldFaces[j][6],detectOldFaces[j][7]));
                }
            }

            //number of rows in the matrix
            var rowNum = detectOldFaces.length;
            //number of columns in the matrix
            var columnNum = numOfFaces;

            //when a best match is found (the difference between a face from the previous frame and the new frame is minimal),
            //all other data containing those faces is erased and the sizes of the matrix are decreased by 1
            //the while loop runs until the matrix is empty (all existing faces have been matched)
            while(rowNum > 0 && columnNum > 0)
            {
                //gives the minimal difference in this iteration
                var difMin = Math.min.apply(Math, destructableArray.map(function(v) {
                    return v[2];
                }));
                //data with the minimal difference, same structure as an element of detectOldFaces
                var currentMin;

                for (var i = 0; i < destructableArray.length; i++)
                {
                    if(destructableArray[i][2] == difMin)
                    {
                        currentMin = destructableArray[i];
                        //deletes the matched row of the matrix
                        destructableArray.splice(currentMin[0] * columnNum, columnNum);
                        rowNum -= 1;
                        //deletes the matched column of the matrix
                        for (var k = 0; k < rowNum; k++)
                        {
                            destructableArray.splice(k * (columnNum-1) + currentMin[1], 1);

                        }
                        columnNum -= 1;

                        //temporary storage for the matches
                        tempDetectOldFaces.push(currentMin);
                        break;
                    }
                }
            }

            //in case there are new faces, creates new data for gender and emotion estimation of those faces
            if(numOfFaces > tempDetectOldFaces.length)
            {
                for (var j = 0; j < numOfFaces; j++)
                {
                    //test to avoid making duplicate data
                    var matchFound = false;
                    for (var i = 0; i < tempDetectOldFaces.length; i++)
                    {
                        if(tempDetectOldFaces[i][1] == j)
                        {
                            matchFound = true;
                            break;
                        }
                    }
                    if(!matchFound)
                    {
                        var fpPos = DfaceData.get(i).getFeaturePoints2D().getFPPos(12,1);
                        tempDetectOldFaces.push(new Array(j,j,0,fpPos[0],fpPos[1],new Array(),new Array(),new Array()));
                    }
                }
            }

            //sorts the data by index in the current frame for easier emotion updating and drawing later
            tempDetectOldFaces.sort(sortFunction);
            //updating the gender and emotion data for further use
            detectOldFaces = tempDetectOldFaces;
        }
    }

    //test if the face from the last frame is the same in this frame (used by tracker)
    //resets gender and emotion data if a new face is tracked
    var allowedDif = 0.2;
    function trackTest(){
        var factorDif = allowedDif * TfaceData.faceScale / canvas.height;
        if(TfaceDataNoseOld.length == 0)
        {
            TfaceDataNoseOld = [TfaceData.getFeaturePoints2D().getFPPos(12,1)[0],TfaceData.getFeaturePoints2D().getFPPos(12,1)[1]];
        }
        else
        {
            if(
                    ((TfaceData.getFeaturePoints2D().getFPPos(12,1)[0] >= (TfaceDataNoseOld[0] - factorDif)) &&
                    (TfaceData.getFeaturePoints2D().getFPPos(12,1)[0] <= (TfaceDataNoseOld[0] + factorDif)))
                    ||
                    ((TfaceData.getFeaturePoints2D().getFPPos(12,1)[1] >= (TfaceDataNoseOld[1] - factorDif)) &&
                    (TfaceData.getFeaturePoints2D().getFPPos(12,1)[1] <= (TfaceDataNoseOld[1] + factorDif)))
            )
            {
                TfaceDataNoseOld = [TfaceData.getFeaturePoints2D().getFPPos(12,1)[0],TfaceData.getFeaturePoints2D().getFPPos(12,1)[1]];
            }
            else
            {
                maleNum = 0;
                femaleNum = 0;
                TfaceDataNoseOld = [TfaceData.getFeaturePoints2D().getFPPos(12,1)[0],TfaceData.getFeaturePoints2D().getFPPos(12,1)[1]];
                trackLastFewEmotionList = new Array();
                trackLastFewAgeList = new Array();
                trackLastFewGenderList = new Array();
            }
        }
    }

    //floating point filter (last 0.5 seconds) for emotion estimation in tracker (improves the presentation of the collected data)
    function trackGenderAndEmotionFilter(emotions,gender,age){
        //updates the emotion data
        trackLastFewEmotionList.push(emotions);
        trackLastFewAgeList.push(age);
        trackLastFewGenderList.push(gender);

        //removes outdated data
        if(trackLastFewEmotionList.length > emotionNumFilterFrames)
        {
            for(i = 0; i < (trackLastFewEmotionList.length - emotionNumFilterFrames); i++)
            {
                trackLastFewEmotionList.shift();
            }
        }

        //age estimation has a 5 second filter
        if(trackLastFewAgeList.length > ageNumFilterFrames)
        {
            for(i = 0; i < (trackLastFewAgeList.length - ageNumFilterFrames); i++)
            {
                trackLastFewAgeList.shift();
            }
        }

        //gender estimation has a 1 second filter
        if(trackLastFewGenderList.length > genderNumFilterFrames)
        {
            for(i = 0; i < (trackLastFewGenderList.length - genderNumFilterFrames); i++)
            {
                trackLastFewGenderList.shift();
            }
        }

        //calculates the emotions applying the filter
        for(i = 0; i < trackLastFewEmotionList.length; i++)
        {
            for(j = 0; j < numberOfEmotions; j++)
            {
                emotionSumList[j] += trackLastFewEmotionList[i][j];
            }
        }
        for(j = 0; j < numberOfEmotions; j++)
        {
            emotionAverageList[j] = emotionSumList[j] / trackLastFewEmotionList.length;
            emotionSumList[j] = 0;
        }

        //calculates the age applying the filter
        for(i = 0; i < trackLastFewAgeList.length; i++)
        {
            AgeSum += trackLastFewAgeList[i];
        }
        AgeAverage = AgeSum / trackLastFewAgeList.length;
        AgeSum = 0;

        //calculates the gender applying the filter
        for(i = 0; i < trackLastFewGenderList.length; i++)
        {
            GenderSum += trackLastFewGenderList[i];
        }
        GenderAverage = Math.round(GenderSum / trackLastFewGenderList.length);
        GenderSum = 0;

        //updates the gender data
        (gender === 1) ? ++maleNum : ++femaleNum;

        //displays gender and emotion data
        canCon.translate(mWidth, 0);
        canCon.scale(-1, 1);
        drawGenderAgeEmotions(emotionAverageList,GenderAverage, AgeAverage);
        canCon.translate(mWidth, 0);
        canCon.scale(-1, 1);
    }

    //floating point filter (last 0.5 seconds) for emotion estimation in detector (improves the presentation of the collected data)
    function detectGenderAndEmotionFilter(index,myGender,myEmotions,myAge){
        //updates the emotion data
        detectOldFaces[index][5].push(myEmotions);
        detectOldFaces[index][6].push(myGender);
        detectOldFaces[index][7].push(myAge);

        var maleNum;
        var femaleNum;

        //updates the gender data

        //removes outdated data
        if(detectOldFaces[index][5].length > emotionNumFilterFrames)
        {
            for(i = 0; i < (detectOldFaces[index][5].length - emotionNumFilterFrames); i++)
            {
                detectOldFaces[index][5].shift();
            }
        }

        //gender estimation has a 1 second filter
        if(detectOldFaces[index][6].length > genderNumFilterFrames)
        {
            for(i = 0; i < (detectOldFaces[index][6].length - genderNumFilterFrames); i++)
            {
                detectOldFaces[index][6].shift();
            }
        }

        //age estimation has a 5 second filter
        if(detectOldFaces[index][7].length > ageNumFilterFrames)
        {
            for(i = 0; i < (detectOldFaces[index][7].length - ageNumFilterFrames); i++)
            {
                detectOldFaces[index][7].shift();
            }
        }

        //calculates the emotions applying the filter
        for(i = 0; i < detectOldFaces[index][5].length; i++)
        {
            for(j = 0; j < numberOfEmotions; j++)
            {
                emotionSumList[j] += detectOldFaces[index][5][i][j];
            }
        }

        for(j = 0; j < numberOfEmotions; j++)
        {
            emotionAverageList[j] = emotionSumList[j] / detectOldFaces[index][5].length;
            emotionSumList[j] = 0;
        }

        //calculates the age applying the filter
        for(i = 0; i < detectOldFaces[index][6].length; i++)
        {
            GenderSum += detectOldFaces[index][6][i];
        }
        GenderAverage = GenderSum / detectOldFaces[index][6].length;
        GenderSum = 0;

        //calculates the age applying the filter
        for(i = 0; i < detectOldFaces[index][7].length; i++)
        {
            AgeSum += detectOldFaces[index][7][i];
        }
        AgeAverage = AgeSum / detectOldFaces[index][7].length;
        AgeSum = 0;



        //displays gender, age and emotion data
        canCon.translate(mWidth, 0);
        canCon.scale(-1, 1);
        drawGenderAgeEmotions(emotionAverageList,GenderAverage,AgeAverage,index);
        canCon.translate(mWidth, 0);
        canCon.scale(-1, 1);
    }

    var numberOfEmotions = 7;
    var emotionAverageList = new Array(0,0,0,0,0,0,0);
    var emotionSumList = new Array(0,0,0,0,0,0,0);
    var AgeSum = 0;
    var AgeAverage = 0;
    var GenderSum = 0;
    var GenderAverage = 0;
    var numOfFaces;
    var gender;
    var emotion;
    var emotions;
    var age;
    var emotionNumFilterFrames = 1;
    var genderNumFilterFrames = 1;
    var ageNumFilterFrames = 1;
    var trackLastFewEmotionList = new Array();
    var trackLastFewAgeList = new Array();
    var trackLastFewGenderList = new Array();

    var detectOldFaces = new Array();

    var fps = 30;
    var now;
    var then = Date.now();
    var interval = 1000/fps;
    var delta;

    //time in seconds in witch the data for emotion, gender and age filter is gathered
    var emotionFilterTime = 0.5;
    var genderFilterTime = 1;
    var ageFilterTime = 5;
    firstRun = true;
    /*
     *Method that is called on every frame via requestAnimationFrame mechanism.
     *Draws camera image on the canvas, takes the pixel data, sends them to the tracker and finally, depending on the result, draws the results.
     *Rudimentary timing is implemented to be activated on button click and it also checks for duplicate frames.
     */
    function processFrame(){
        window.requestAnimationFrame(processFrame);

        now = Date.now();
        delta = now - then;

        if(firstRun)
        {
            firstRun = false;
            trackText.style.display = "block";
            opacityControl();
        }

        //Limit frame rate according to the fps variable
        if (delta > interval)
        {
            then = now - (delta % interval);

            canvas.width = mWidth;
            //Draws an image from cam on the canvas
            canCon.drawImage(video,0,0,mWidth,mHeight);

            //Access pixel data
            imageData = canCon.getImageData(0,0, mWidth, mHeight).data;

            //Save pixel data to preallocated buffer
            for(i=0; i<imageData.length; i+=1)
            {
                pixels[i] = imageData[i];
            }

            //If tracker is used
            if(activeMode == MODE_TRACK)
            {
                if (startTracking===true)
                {
                    trackerReturnState = m_Tracker.track(
                            mWidth, mHeight,ppixels, TfaceData,
                            Module.VisageTrackerImageFormat.VISAGE_FRAMEGRABBER_FMT_RGBA.value,
                            Module.VisageTrackerOrigin.VISAGE_FRAMEGRABBER_ORIGIN_TL.value,
                            0,
                            -1
                    );
                }
                //Draw based upon data if tracker status is OK and respective controls
                if (startTracking===true && trackerReturnState===Module.VisageTrackerStatus.TRACK_STAT_OK.value){
                    if (draw === true){
                        if(statusFeaturePoints)
                        {
                            drawFaceFeatures(TfaceData);
                        }
                        if(statusGaze)
                        {
                            drawGaze(TfaceData);
                        }
                        if(statusFMA)
                        {
                            drawFaceModelAxes(TfaceData);
                        }
                    }

                    //checks if a new face is being tracked, if so resets gender and emotion data from previous frames
                    trackTest();

                    if (draw === true && (drawEmotions || drawAge || drawGender))
                    {
                        var emotions = new Module.VectorFloat();
                        var emotionsArray = [];
                        emotion = m_FaceAnalyser.estimateEmotion(mWidth, mHeight, ppixels, TfaceData,emotions);
                        gender = m_FaceAnalyser.estimateGender(mWidth, mHeight, ppixels, TfaceData);
                        age = m_FaceAnalyser.estimateAge(mWidth, mHeight, ppixels, TfaceData);

                        //number of frames to be remembered for emotion, age and gender filter
                        emotionNumFilterFrames = Math.max(Math.round(emotionFilterTime*thisFrameFPS),1);
                        genderNumFilterFrames = Math.max(Math.round(genderFilterTime*thisFrameFPS),1);
                        ageNumFilterFrames = Math.max(Math.round(ageFilterTime*thisFrameFPS),1);

                        //calls gender, age and emotion filtering and drawing
                        if (emotion && gender >= 0 && age >=0)
                        {
                            for (var i = 0; i < numberOfEmotions; ++i)
                            {
                                emotionsArray.push(emotions.get(i));
                            }
                            emotions.delete();
                            trackGenderAndEmotionFilter(emotionsArray,gender,age);
                        }
                    }

                    transOutput.innerHTML = "[" + TfaceData.getFaceTranslation()[0].toFixed(2) + "," + TfaceData.getFaceTranslation()[1].toFixed(2) + "," + TfaceData.getFaceTranslation()[2].toFixed(2) + "]";
                    rotOutput.innerHTML = "[" + TfaceData.getFaceRotation()[0].toFixed(2) + "," + TfaceData.getFaceRotation()[1].toFixed(2) + "," + TfaceData.getFaceRotation()[2].toFixed(2) + "]";
                }
                if (trackerReturnState !== Module.VisageTrackerStatus.TRACK_STAT_OK.value)
                {
                    maleNum = 0;
                    femaleNum = 0;
                    TfaceDataNoseOld = new Array();
                    trackLastFewEmotionList = new Array();
                    trackLastFewAgeList = new Array();
                    trackLastFewGenderList = new Array();
                }
                statOutput.innerHTML = "[" + trackerStates[trackerReturnState] + "]";
            }


            //If detector is used
            if(activeMode == MODE_DETECT)
            {
                if (startDetecting===true)
                {
                    numOfFaces = m_Detector.detectFeatures(mWidth,mHeight,ppixels,DfaceData, maxFaces, minFaceScale);
                }
                //Draw based upon data
                if (startDetecting===true && numOfFaces > 0)
                {
                    if(statusFeaturePoints)
                    {
                        for (var i = 0; i < numOfFaces; i++)
                        {
                            drawFaceFeatures(DfaceData.get(i),i);
                        }
                    }

                    //Matches faces from the previous frames with faces from the current frame. Keeps the consistency of gender and emotion data.
                    matchFaces();

                    //number of frames to be remembered for emotion, age and gender filter
                    emotionNumFilterFrames = Math.round(emotionFilterTime*thisFrameFPS);
                    genderNumFilterFrames = Math.round(genderFilterTime*thisFrameFPS);
                    ageNumFilterFrames = Math.round(ageFilterTime*thisFrameFPS);

                    //gender, age and emotion estimation, filtering and drawing
                    if (drawEmotions || drawAge || drawGender)
                    {
                        for (var i = 0; i < numOfFaces; i++)
                        {
                            var emotions = new Module.VectorFloat();
                            var emotionsArray = [];
                            gender = m_FaceAnalyser.estimateGender(mWidth, mHeight, ppixels, DfaceData.get(i));
                            emotion = m_FaceAnalyser.estimateEmotion(mWidth, mHeight, ppixels, DfaceData.get(i), emotions);
                            age = m_FaceAnalyser.estimateAge(mWidth, mHeight, ppixels, DfaceData.get(i));
                            //
                            if (emotion && gender >= 0 && age >=0)
                            {
                                for (var j = 0; j < numberOfEmotions; ++j)
                                {
                                    emotionsArray.push(emotions.get(j));
                                }
                                emotions.delete();
                                detectGenderAndEmotionFilter(i,gender,emotionsArray,age);
                            }
                        }
                    }
                }
            }
            //Calculate FPS
            thisFrameFPS = 1000 / ((now=new Date) - lastUpdate);
            fps += (thisFrameFPS - fps) / fpsFilter;
            lastUpdate = now;

            decOpacity();
        }
    }
    //Function called when Start is clicked, tracking/detecting is resumed/started
    function StartTracker(){

        startTracking = true;
    }

    function StopTracker(){
        startTracking = false;
    }

    function StartDetector(){

        startDetecting = true;
    }

    function StopDetector(){
        startDetecting = false;
    }

    /*
     **Info text fade-out controls
     */
    var decOpacityEnabled = false;
    var decTime = 5;

    function decOpacity()
    {
        if(currentOpacity > 0 && decOpacityEnabled)
        {
            currentOpacity = Math.max(currentOpacity - 1/(fps*decTime), 0);
            detectText.style.opacity = currentOpacity;
            trackText.style.opacity = currentOpacity;
        }
        else
        {
            decOpacityEnabled = false;
        }
    }

    function opacityControl()
    {
        currentOpacity = 1.00;
        detectText.style.opacity = currentOpacity;
        trackText.style.opacity = currentOpacity;
        setTimeout(function(){
            decOpacityEnabled = true;
        }, 2000);
    }

    /*
     ***Tracker and detector swich contol
     */
    var detectText = document.getElementById('detecttext');
    var trackText = document.getElementById('tracktext');

    function ToggleTrackDetect(){
        var results = document.getElementsByClassName('vanishing');
        if(activeMode == MODE_TRACK){
            activeMode = MODE_DETECT;
            document.getElementById("tooltiptext").innerHTML = "TRACKER: Single-face tracking, higher performance and accuracy.";
            document.getElementById('optionGaze').style.display = "none";
            document.getElementById('optionFMA').style.display = "none";
            for(i=0; i<results.length; i++)
            {
                results[i].style.display = "none";
            }
            document.getElementById('ToggleTD').innerHTML = "Switch to Tracker";
            detectText.style.display = "block";
            trackText.style.display = "none";

            opacityControl();

            StopTracker();
            StartDetector();
        }
        else if(activeMode == MODE_DETECT){
            activeMode = MODE_TRACK;
            document.getElementById("tooltiptext").innerHTML = "DETECTOR: Multiple face detection, lower performance and accuracy.";
            document.getElementById('optionGaze').style.display = "inline";
            document.getElementById('optionFMA').style.display = "inline";
            for(i=0; i<results.length; i++)
            {
                results[i].style.display = "inline";
            }
            document.getElementById('ToggleTD').innerHTML = "Switch to Detector";
            detectText.style.display = "none";
            trackText.style.display = "block";

            opacityControl();

            StopDetector();
            StartTracker();
        }
        maleNum = 0;
        femaleNum = 0;
    }

    var m_Tracker;
    var m_Detector;
    var TfaceData;
    var DfaceData
    var maxFaces = 20;
    var imageData;
    var m_FaceAnalyser;

    var TfaceDataNoseOld = new Array();

    var video = document.createElement('video');

    //Handlers for camera communication
    //callback methods for getUserMedia : deniedStream, errorStream, startStream
    //**************************************************************************

    //Alerts the user when there is no camera
    function deniedStream(){
        alert("Camera access denied!)");
    }
    //Pushes error to the console when there is error with camera access
    function errorStream(e){
        if (e){
            console.error(e);
        }
    }

    function initial(){
        var canvas = document.getElementById('canvas');
        canvas.style.display = "block";
        var logogrey = document.getElementById('logogrey');
        logogrey.style.display = "none";
    }

    function onModuleInitialized()
    {
        if (mWidth === 0)
        {
            setTimeout(onModuleInitialized, 100);
            return
        }

        ppixels = Module._malloc(mWidth*mHeight*4);
        pixels = new Uint8ClampedArray(Module.HEAPU8.buffer, ppixels, mWidth*mHeight*4);

        //set up tracker and licensing, valid license needs to be provided
        Module.initializeLicenseManager("609-917-367-102-315-052-186-423-185-386-124.vlc");
        m_Tracker = new Module.VisageTracker("../../lib/Facial Features Tracker - High.cfg");
        TfaceData = new Module.FaceData();

        //set up detector and licensing, valid license needs to be provided
        m_Detector = new Module.VisageDetector();
        DfaceData = new Module.FaceDataVector();
        for (var i = 0; i < maxFaces; ++i)
        {
            DfaceData.push_back(new Module.FaceData());
        }

        //set up face analysis
        m_FaceAnalyser = new Module.VisageFaceAnalyser();

        maleNum = 0;
        femaleNum = 0;

        //Use request animation frame mechanism - slower but with smoother animation
        processFrame();
    }

    //Is triggered when cam stream is successfully fetched
    //NOTE: Can be buggy, try to increase the value from 1000ms to some higher value in that case
    function startStream(stream){
        video.addEventListener('canplay', function DoStuff() {
            video.removeEventListener('canplay', DoStuff, true);
            setTimeout(function() {
                video.play();

                canvas.width = Math.min(video.videoWidth, Math.max(document.documentElement.clientWidth/2,0));
                canvas.height = Math.min(video.videoHeight, Math.max(Math.round(video.videoHeight*(document.documentElement.clientWidth/2)/video.videoWidth),0));

                mWidth = canvas.width;
                mHeight = canvas.height;

                //initial visual elements of the sample
                initial();
            }, 1000);
        }, true);

        var domURL = window.URL || window.webkitURL;
        video.src = domURL ? domURL.createObjectURL(stream) : stream;

        video.play();
    }

    //Different browser support for fetching camera stream
    window.URL = window.URL || window.webkitURL;
    navigator.getUserMedia_ =  navigator.getUserMedia || navigator.webkitGetUserMedia ||
            navigator.mozGetUserMedia || navigator.msGetUserMedia;

    var video_constraints = {
        width: { min: 1920, max: 1920 },
        height: { min: 1080, max: 1080 },
        require: ["width", "height"] // needed pre-Firefox 38 (non-spec)
    };

    (function() {
        var i = 0,
                lastTime = 0,
                vendors = ['ms', 'moz', 'webkit', 'o'];

        while (i < vendors.length && !window.requestAnimationFrame) {
            window.requestAnimationFrame = window[vendors[i] + 'RequestAnimationFrame'];
            window.cancelAnimationFrame =
                    window[vendors[i]+'CancelAnimationFrame'] || window[vendors[i]+'CancelRequestAnimationFrame'];
            i++;
        }
        if (!window.requestAnimationFrame) {
            alert("RequestAnimationFrame mechanism is not supported by this browser.");
        }
    }());

    //Here is where the stream is fetched
    try {
        navigator.getUserMedia_({
            video: true,
            audio: false
        }, startStream, deniedStream);
    } catch (e) {
        try {
            navigator.getUserMedia_({video: video_constraints, startStream, deniedStream});
        } catch (e) {
            errorStream(e);
        }
    }
    video.loop = video.muted = true;
    video.autoplay = true;
    video.load();


</script>

<script src="./lib/visageSDK.js"></script>

</body>
</html> 